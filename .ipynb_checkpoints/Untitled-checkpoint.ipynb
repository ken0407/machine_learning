{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Age', 'Fare', 'female', 'family', 'isAlone', 'te_embarked']\n",
      "['Pclass', 'Age', 'Fare', 'female', 'family', 'isAlone', 'ce_embarked']\n",
      "['Pclass', 'Age', 'Fare', 'female', 'family', 'isAlone', 'lce_embarked']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Target_Encoding</th>\n",
       "      <td>0.783282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count_Encoding</th>\n",
       "      <td>0.778475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelCount_Encoding</th>\n",
       "      <td>0.776872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        score\n",
       "Target_Encoding      0.783282\n",
       "Count_Encoding       0.778475\n",
       "LabelCount_Encoding  0.776872"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"./input/titanic/train.csv\")\n",
    "test = pd.read_csv(\"./input/titanic/test.csv\")\n",
    "\n",
    "train[\"female\"] = train[\"Sex\"].apply(lambda x:1 if x=='female' else 0)\n",
    "train.drop(\"Sex\",axis=1,inplace=True)\n",
    "test[\"female\"] = test[\"Sex\"].apply(lambda x:1 if x=='female' else 0)\n",
    "test.drop(\"Sex\",axis=1,inplace=True)\n",
    "\n",
    "male_class1_age_mean = train[(train[\"female\"]==0) & (train[\"Pclass\"]==1)][\"Age\"].mean()\n",
    "male_class2_age_mean = train[(train[\"female\"]==0) & (train[\"Pclass\"]==2)][\"Age\"].mean()\n",
    "male_class3_age_mean = train[(train[\"female\"]==0) & (train[\"Pclass\"]==3)][\"Age\"].mean()\n",
    "male_class1_age_std = train[(train[\"female\"]==0) & (train[\"Pclass\"]==1)][\"Age\"].std()\n",
    "male_class2_age_std = train[(train[\"female\"]==0) & (train[\"Pclass\"]==2)][\"Age\"].std()\n",
    "male_class3_age_std = train[(train[\"female\"]==0) & (train[\"Pclass\"]==3)][\"Age\"].std()\n",
    "\n",
    "female_class1_age_mean = train[(train[\"female\"]==1) & (train[\"Pclass\"]==1)][\"Age\"].mean()\n",
    "female_class2_age_mean = train[(train[\"female\"]==1) & (train[\"Pclass\"]==2)][\"Age\"].mean()\n",
    "female_class3_age_mean = train[(train[\"female\"]==1) & (train[\"Pclass\"]==3)][\"Age\"].mean()\n",
    "female_class1_age_std = train[(train[\"female\"]==1) & (train[\"Pclass\"]==1)][\"Age\"].std()\n",
    "female_class2_age_std = train[(train[\"female\"]==1) & (train[\"Pclass\"]==2)][\"Age\"].std()\n",
    "female_class3_age_std = train[(train[\"female\"]==1) & (train[\"Pclass\"]==3)][\"Age\"].std()\n",
    "\n",
    "train[\"Age\"] = train[\"Age\"].fillna(-1)\n",
    "test[\"Age\"] = test[\"Age\"].fillna(-1)\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    if train.iloc[i][\"Age\"] == -1:\n",
    "        if (train.iloc[i]['female']==0) & (train.iloc[i]['Pclass']==1):\n",
    "            train.iat[i,4] = int(np.random.normal(male_class1_age_mean,male_class1_age_std))\n",
    "        elif (train.iloc[i]['female']==0) & (train.iloc[i]['Pclass']==2):\n",
    "            train.iat[i,4] = int(np.random.normal(male_class2_age_mean,male_class2_age_std))\n",
    "        elif (train.iloc[i]['female']==0) & (train.iloc[i]['Pclass']==3):\n",
    "            train.iat[i,4] = int(np.random.normal(male_class3_age_mean,male_class3_age_std))\n",
    "        elif (train.iloc[i]['female']==1) & (train.iloc[i]['Pclass']==1):\n",
    "            train.iat[i,4] = int(np.random.normal(female_class1_age_mean,female_class1_age_std))\n",
    "        elif (train.iloc[i]['female']==1) & (train.iloc[i]['Pclass']==2):\n",
    "            train.iat[i,4] = int(np.random.normal(female_class2_age_mean,female_class2_age_std))\n",
    "        elif (train.iloc[i]['female']==1) & (train.iloc[i]['Pclass']==3):\n",
    "            train.iat[i,4] =int(np.random.normal(female_class3_age_mean,female_class3_age_std))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in range(test.shape[0]):\n",
    "    if test.iloc[i][\"Age\"] == -1:\n",
    "        if (test.iloc[i]['female']==0) & (test.iloc[i]['Pclass']==1):\n",
    "            test.iat[i,4] = np.random.normal(male_class1_age_mean,male_class1_age_std)\n",
    "        elif (test.iloc[i]['female']==0) & (test.iloc[i]['Pclass']==2):\n",
    "            test.iat[i,4] = np.random.normal(male_class2_age_mean,male_class2_age_std)\n",
    "        elif (test.iloc[i]['female']==0) & (test.iloc[i]['Pclass']==3):\n",
    "            test.iat[i,4] = np.random.normal(male_class3_age_mean,male_class3_age_std)\n",
    "        elif (test.iloc[i]['female']==1) & (test.iloc[i]['Pclass']==1):\n",
    "            test.iat[i,4] = np.random.normal(female_class1_age_mean,female_class1_age_std)\n",
    "        elif (test.iloc[i]['female']==1) & (test.iloc[i]['Pclass']==2):\n",
    "            test.iat[i,4] = np.random.normal(female_class2_age_mean,female_class2_age_std)\n",
    "        elif (test.iloc[i]['female']==1) & (test.iloc[i]['Pclass']==3):\n",
    "            test.iat[i,4] = np.random.normal(female_class3_age_mean,female_class3_age_std)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "train[\"family\"] = train[\"SibSp\"] + train[\"Parch\"]\n",
    "train.drop([\"SibSp\",\"Parch\",\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace=True)\n",
    "test[\"family\"] = test[\"SibSp\"] + test[\"Parch\"]\n",
    "test.drop([\"SibSp\",\"Parch\",\"Name\",\"Ticket\",\"Cabin\"],axis=1,inplace=True)\n",
    "train[\"isAlone\"] = train[\"family\"].apply(lambda x:1 if x==0 else 0)\n",
    "test[\"isAlone\"] = test[\"family\"].apply(lambda x:1 if x==0 else 0)\n",
    "\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(np.mean(test[\"Fare\"]))\n",
    "\n",
    "#target_encording\n",
    "te_embarked_map = {\"S\":np.mean(train[train[\"Embarked\"]==\"S\"][\"Survived\"]),\"C\":np.mean(train[train[\"Embarked\"]==\"C\"][\"Survived\"]),\"Q\":np.mean(train[train[\"Embarked\"]==\"Q\"][\"Survived\"])}\n",
    "train[\"te_embarked\"] = train[\"Embarked\"].apply(lambda x: te_embarked_map[x])\n",
    "test[\"te_embarked\"] = test[\"Embarked\"].apply(lambda x: te_embarked_map[x])\n",
    "\n",
    "#count_encording\n",
    "ce_embarked_map = {\"S\":len(train[train[\"Embarked\"]==\"S\"]),\"C\":len(train[train[\"Embarked\"]==\"C\"]),\"Q\":len(train[train[\"Embarked\"]==\"Q\"])}\n",
    "train[\"ce_embarked\"] = train[\"Embarked\"].apply(lambda x: ce_embarked_map[x])\n",
    "test[\"ce_embarked\"] = test[\"Embarked\"].apply(lambda x: ce_embarked_map[x])\n",
    "\n",
    "#label_count_encoding\n",
    "sorted_nums = np.sort(np.unique(train[\"ce_embarked\"]))[::-1]\n",
    "rank_map = {\"{}\".format(num) : i+1 for i,num in enumerate(sorted_nums)}\n",
    "train[\"lce_embarked\"] = train[\"ce_embarked\"].apply(lambda x: rank_map[str(x)])\n",
    "test[\"lce_embarked\"] = test[\"ce_embarked\"].apply(lambda x: rank_map[str(x)])\n",
    "\n",
    "train.drop(\"Embarked\",axis=1,inplace=True)\n",
    "test.drop(\"Embarked\",axis=1,inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "cols = list(train.columns)\n",
    "\n",
    "train_X,test_X,train_y,test_y = train_test_split(train[cols[2:]],train[cols[1]],test_size=0.3,random_state=1234)\n",
    "\n",
    "train_X.to_csv(\"mod_train.csv\",index=False)\n",
    "\n",
    "ss = StandardScaler()\n",
    "train_X_std = pd.DataFrame(ss.fit_transform(train_X),columns=cols[2:])\n",
    "train_X_std.to_csv(\"std_mod_train.csv\",index=False)\n",
    "\n",
    "ms = MinMaxScaler()\n",
    "train_X_mm = pd.DataFrame(ms.fit_transform(train_X),columns=cols[2:])\n",
    "train_X_mm.to_csv(\"minmax_mod_train.csv\",index=False)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from copy import copy\n",
    "base_cols = cols[2:-3]\n",
    "encoded_Emb_cols = cols[-3:]\n",
    "scores = []\n",
    "\n",
    "for col_name in encoded_Emb_cols:\n",
    "    tmp_cols = copy(base_cols)\n",
    "    tmp_cols.append(col_name)\n",
    "    print(tmp_cols)\n",
    "    clf = LogisticRegression()\n",
    "    score = cross_val_score(clf, train_X_std[tmp_cols] , train_y, cv=3)\n",
    "    scores.append(np.mean(score))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(np.array(scores),columns=[\"score\"],index=[\"Target_Encoding\",\"Count_Encoding\",\"LabelCount_Encoding\"])#,columns=[\"Target_Encoding\",\"Count_Encoding\",\"LabelCount_Encoding\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-113db0bf9b4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras.layer import Input,Dense,Dropout\n",
    "from keras.optimizer import Adam\n",
    "\n",
    "def build_model(x):\n",
    "    dr = 0.3\n",
    "    lr =0.1\n",
    "    model = Models()\n",
    "    input = Dense(x.shape[1])\n",
    "    x = Dropout(dr)(Dense(30,activation=\"relu\")(x))\n",
    "    x = Dropout(dr)(Dense(50,activation=\"relu\")(x))\n",
    "    x = Dense(1,activation=\"sigmoid\")(x)\n",
    "    model = Model(input,x)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=Adam(lr=lr))\n",
    "    return model\n",
    "model = build_model(features)\n",
    "model.fit(features,target,batch_size=60,epoch=100)\n",
    "pred = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
